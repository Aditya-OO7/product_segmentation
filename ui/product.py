import streamlit as st
import pandas as pd
from processing.product import (
    load_local,
    load_upload)
import base64

def upload_ui():
    st.subheader('Load a Dataset üíæ')
    # Upload
    input_file = st.file_uploader("Upload your dataset (.csv)")
    if input_file is None:
        dataset_type = 'LOCAL'
        st.write(
            "_If you do not upload a dataset, an example is automatically loaded to show you the features of this app._")
        df_abc, df = load_local()
        date_col, metric_col, list_var, list_sku, family_col = dataset_ui(df_abc, df, dataset_type)
    else:
        dataset_type = 'UPLOADED'
        with st.spinner('Loading data..'):
            df = load_upload(input_file)
            st.write(df.head())
            df_abc = pd.DataFrame()
        date_col, metric_col, list_var, list_sku, family_col = dataset_ui(df_abc, df, dataset_type)

    # Process filtering
    st.write("\n")
    st.subheader('''üìä Your dataset with the final version of the features''')
    df = df[list_var].copy()
    st.write(df.head(2))

    return date_col, metric_col, list_var, list_sku, family_col, dataset_type, df, df_abc


def dataset_ui(df_abc, df, dataset_type):
    # SHOW PARAMETERS
    expander_default = (dataset_type == 'UPLOADED')

    st.subheader('üõéÔ∏è Please choose the following features in your dataset')
    with st.expander("FEATURES TO USE FOR THE ANALYSIS"):
        st.markdown('''
        _Select the columns that you want to include in the analysis of your sales records._
    ''')
        dict_var = {}
        for column in df.columns:
            dict_var[column] = st.checkbox("{} (IN/OUT)".format(column), value=1)
    filtered = filter(lambda col: dict_var[col] == 1, df.columns)
    list_var = list(filtered)

    with st.expander("FEATURES FOR THE DATES AND THE VALUES"):
        columns = list_var
        col1, col2 = st.columns(2)
        with col1:
            date_col = st.selectbox("Select date column", index=len(columns) - 2, options=columns, key="date")
        with col2:
            metric_col = st.selectbox("Select values column", index=len(columns) - 1, options=columns, key="values")
        output = 0

    with st.expander("FEATURE FOR THE SKU INFORMATION (ITEM ID)"):
        st.markdown('''
        _Select the columns used for product master data (SKU ID, Family, Category, Store Location)_
    ''')
        sku_col = st.selectbox("Select values column", index=1, options=list_var, key="values")

    with st.expander("FEATURE FOR THE SKU FAMILY"):
        st.markdown('''
        _Select the column you want to use to group your SKUs (Category, Sub-Category, Department)_
    ''')
        family_col = st.selectbox("Select a column for the product family", index=3, options=list_var, key="date")

    return date_col, metric_col, list_var, sku_col, family_col


def pareto_ui(df_abc, nsku_qty80, qty_nsku20):
    col1, col2 = st.columns(2)
    with col1:
        st.write('80% of your volume is generated by **{}% for your SKU portofolio**'.format(nsku_qty80))
    with col2:
        st.write('20% of your SKU portofolio represent **{}% for your volume**'.format(qty_nsku20))


def abc_ui(df, family_col):
    st.header("**ABC Analysis with Demand Variability üî§**")
    col1, col2 = st.columns(2)
    with col1:
        interval = st.slider(
            'SET THE MAXIMUM VALUE FOR Y-AXIS CV',
            0,
            int(df['CV'].max())
            , value=4)

    dict_family = {}
    with st.expander("SELECT THE SKU FAMILIES YOU WANT TO INCLUDE IN THE CHART"):
        for miff in df[family_col].unique():
            dict_family[miff] = st.checkbox("{} (YES/NO)".format(miff), value=1)
    filtered = filter(lambda col: dict_family[col] == 1, df[family_col].unique())
    list_family = list(filtered)

    return interval, list_family


def normality_ui():
    st.header("**Normality Test ‚úîÔ∏è**")
    st.markdown(
        '''_Can we reject the null hypothesis that the sales distribution of the item follows a normal distribution?_
        ''')
    st.markdown(
        '''
This model is using the Shapiro-Wilk test for normality implemented using Scipy library of python 
_(**[Documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html)**)_.
''')


def distribution_ui():
    st.header("**Example of distributions with a low CV üìü**")
    st.markdown(
        '''
        _A rule of thumb to estimate the normality of a distribution is to 
        assume that below 0.5 you can assumte that the distribution is normal._
        ''')


def export_ui(rfm):
    st.header('**Export results ‚ú®**')
    st.write("_Finally you can export the results of your segmentation with all the parameters calculated._")
    if st.checkbox('Export Data', key='show'):
        with st.spinner("Exporting.."):
            st.write(rfm.head())
            rfm = rfm.to_csv(decimal=',')
            b64 = base64.b64encode(rfm.encode()).decode()
            href = f'<a href="data:file/csv;base64,{b64}">Download CSV File</a>'
            st.markdown(href, unsafe_allow_html=True)
